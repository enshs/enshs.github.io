---
layout: single
title: "Descriptive Statistics"
categories:
  - Statistics
tags:
  - statistics
  - python
use_math: true
comments: true
---

# Descriptive statistics
## Types of variables

All data generated by measurement, surveys, research, etc. can be variables and also use the term **feature** in machine learning. An event contains multiple variable values and is called an **instance**. The following table contains three variables: name, age, gender, height, and three events: instances. A typical form of data, each variable consists of a column and an instance of a row, which is called a dataset.


|name| 	age	| sex	| height|
|:----:|:----:|:----:|:----:|
|A	| 10| 	male| 	153|
|B| 	15| 	female	| 161|
|C	| 21| 	male	| 181|

In constructing a dataset, the number of questions equals the number of variables, and the number of respondents affects the number of observations. However, the number of respondents does not affect the number of variables.

As shown in Table 1.1, all variables are separated by categorical variables and quantitative variables, and variables are separated by nominal, ordinal, discrete, and continuous, depending on the measurement level.

<table style="border:2px solid;">
    <caption><center><b> Types of variables</b></center></caption>
    <tbody>
        <tr>
            <th style="border:1px solid;text-align:left;width:40%">Variable</th>
            <th style="border:1px solid; text-align:left;width:30%">Contents</th>
            <th style="border:1px solid; text-align:left;width:30%">Level</th>
        </tr>
        <tr>
            <td rowspan="2", style="border:1px solid; text-align:left;">Categorical variables</td>
            <td rowspan=2, style="border:1px solid;text-align:left;">Group(Class)</td>
            <td style="border:1px solid;text-align:left;">Nominal</td>
        </tr>
		<tr>
            <td style="border:1px solid;text-align:left;">Ordinal</td>
            <tr>
      <tr>
            <td rowspan=2, style="border:1px solid; text-align:left;">Quantitative variables</td>
            <td rowspan=2, style="border:1px solid;text-align:left;">Quantity(Size)</td>
            <td style="border:1px solid;text-align:left;">Discrete</td>
        </tr>
		<tr>
            <td style="border:1px solid;text-align:left;">Continuous</td>
            <tr>
    </tbody>
</table>

**Nominal variables** are variables that can only be qualitative classified without logical order. For example, for a dataset of fruits, 1=apples, 2=folds, and 3=watermelons, each fruit is numbered 1, 2 and 3, but the fruit is logically irrelevant between rank and other values. You can only give a name.

Movies can be ranked using rating data that is given within a certain range. However, ratings are subjective evaluations and the intervals between each rating are not constant either. These variables are called **ordinal variables**.

For quantitative variables, measurement levels have their own ranks, and differences between them are measurable and interrelated. Also, the figure itself is meaningful. Therefore, for the same level, it has the same meaning. For these measurement levels, they are divided into countable variables and uncountable parts, respectively, called **discrete** and **continuous**. Discrete refers to a form that can be represented as an integer, such as a population belonging to a certain group, and continuous refers to a form of proportion to absolute criteria such as temperature, height, weight, etc.

<span style="color:blue;"><b>Example 1)</b></span><br>
&emsp; Determine the measurement level of the following variables:

-  Age: discrete, there is a clear measure of measurement, and the difference between ages is meaningful. 
- Party Name: Nominal, this variable can only classify names.  
- Weight: Continuous, absolute reference value 0 exists. You can generate figures proportionally based on zero, but you cannot represent them in clear numbers, such as natural numbers or integers. 
- If students are grouped into three groups A, B, and C, the variable 'group': nominal 
- If players A, B, and C are participating in steps 5, 2 and 3 respectively, then the variable "Step": ordinal. For this variable, the differences within or between steps are not necessarily equal.
- The movie was evaluated on a 5-point scale such as very good, good,... The level of the variable in this outcome: ordinal, in this survey, ordinal number are important. However, the difference between those intervals is not equal.
- City Name: Nominal. You can just give it a name, but you can't rank it.
- People's bank balances: continuous. The difference between each value is the same, and the value itself has meaning. 

### ratio
Distinguish between absolute and relative proportions.
- absolute proportion: part of a whole
- Relative Ratio: Increase or decrease relative to another ratio

The reason for the news that a city is not safe with the increase in crime cases is probably the rate of increase. If this news is added with information about a 50% increase in the homicide rate, it gives the basis for the news that it will get worse, but it's still incomplete. Its incompleteness is due to the lack of information about the number of events being compared, such as an increase from 2 to 3 or an increase from 10 to 4. That is, an increase of 50% is for an increase over the number of past events. Previous figures are needed for complete information. In this case, 50% is a relative ratio, and information about the absolute ratio is needed to fully understand this news. For example, in a city with a population of 100,000 people, if 3 cases occurred compared to 2 cases in the previous year, the increase would be 50%, but an absolute increase of 0.2% to 0.3% would significantly weaken the basis of the negative news. As such, the meaning of relative and absolute ratios is very important, and reporting only relative ratios should be avoided.

The following shows the change in population density in Seoul and the  neighboring metropolitan area, and unlike the above case, a clear trend is shown by the relative ratio. 

<table style="border:2px solid;">    
    <tbody>
        <tr>
            <th style="border:1px solid;text-align:left;"></th>
            <th colspan=2, style="border:1px solid; text-align:center;width:40%">Seoul</th>
            <th colspan=2, style="border:1px solid; text-align:center;width:40%">neighboring</th>
        </tr>
        <tr>
            <td style="border:1px solid; text-align:center;">Year</td>
            <td style="border:1px solid; text-align:center;">Density</td>
            <td style="border:1px solid; text-align:center;">Relative ratio(%) </td>
            <td style="border:1px solid; text-align:center;">Density</td>
            <td style="border:1px solid; text-align:center;">Relative ratio(%) </td>
        </tr>
		<tr>
            <td style="border:1px solid; text-align:center;">2106</td>
            <td style="border:1px solid; text-align:center;">16263</td>
            <td style="border:1px solid; text-align:center;">- </td>
            <td style="border:1px solid; text-align:center;">25350</td>
            <td style="border:1px solid; text-align:center;">-</td>
        </tr>
        <tr><td style="border:1px solid; text-align:center;">2017</td>
            <td style="border:1px solid; text-align:center;">	16136</td>
            <td style="border:1px solid; text-align:center;">	-0.78</td>
            <td style="border:1px solid; text-align:center;">	25476</td>
            <td style="border:1px solid; text-align:center;">	0.50</td>
        </tr>
        <tr>
            <td style="border:1px solid; text-align:center;">2018</td><td style="border:1px solid; text-align:center;">	16034</td><td style="border:1px solid; text-align:center;">-0.63</td><td>	25675</td><td style="border:1px solid; text-align:center;">	0.78</td>
        </tr>
        <tr>
            <td style="border:1px solid; text-align:center;">2019</td><td style="border:1px solid; text-align:center;">	15964</td><td style="border:1px solid; text-align:center;">	-0.44</td><td style="border:1px solid; text-align:center;">	25844</td><td style="border:1px solid; text-align:center;">	0.66</td>
        </tr>    
    </tbody>
</table>

## Location information
### Mode
Statistics often use information about where most of the data is concentrated. These points are called centroid scales. For example, in a restaurant with multiple menus, after a renovation, the manager wants to focus on one menu. In this case, choosing the menu with the most sales is a reasonable decision. The most observed value is called the <span style="color:teal;"><b>mode</b></span>. 

<div style="width:70%; border: 1px solid; border-radius: 5px; margin: 50px; padding:10px">
    <b>mode</b><br>
- The value with the highest frequency based on the number of occurrences of each variable in the data set is called the mode.
- In a data set, there can be more than one mode.
   </div>

The mode value is used to indicate the peak, which is the highest frequency, and this value can be checked with the ``np.unique()`` and ``scipy.stats.mode()`` functions and the ``pd_object.mode()`` method. Also, the frequency of each value in the data can be calculated using the ``np.unique()`` function and the ``pd_object.value\_counts()`` method. 

Next, try to determine the mode from the generated data using ``randint(start, end, size)`` of numpy.random module, a function that generates a random integer of a specified size in a specific interval. 


```python
import numpy as np
import pandas as pd
```


```python
data=np.random.randint(1, 10, 50)
print(data)
```

    [4 6 5 2 8 8 2 2 2 4 5 6 3 4 3 2 1 5 5 3 2 1 7 2 2 3 2 7 9 9 4 7 2 2 3 2 9
     6 5 2 9 2 3 8 7 3 4 4 9 2]



```python
new, cnt=np.unique(data, return_counts=True)
print(new)
print(cnt)
```

    [1 2 3 4 5 6 7 8 9]
    [ 2 15  7  6  5  3  4  3  5]



```python
da1=pd.DataFrame(data)
da1.T
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>40</th>
      <th>41</th>
      <th>42</th>
      <th>43</th>
      <th>44</th>
      <th>45</th>
      <th>46</th>
      <th>47</th>
      <th>48</th>
      <th>49</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4</td>
      <td>6</td>
      <td>5</td>
      <td>2</td>
      <td>8</td>
      <td>8</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>4</td>
      <td>...</td>
      <td>9</td>
      <td>2</td>
      <td>3</td>
      <td>8</td>
      <td>7</td>
      <td>3</td>
      <td>4</td>
      <td>4</td>
      <td>9</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 50 columns</p>
</div>




```python
da1.value_counts()
```




    2    15
    3     7
    4     6
    5     5
    9     5
    7     4
    6     3
    8     3
    1     2
    dtype: int64




```python
da1.mode()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>



The ``unique()`` function calculates the frequency of the entire data, not just the mode, and the user ultimately has to decide the mode. Instead, the  ``pd_object.mode()`` method or the ``stats.mode()`` function returns only the mode, as shown in the following code.



```python
from scipy import stats
```


```python
stats.mode(data)
```




    ModeResult(mode=array([2]), count=array([15]))



<span style="color:blue;"><b>Example 2)</b></span> Try to determine the mode in the object for the color it follows. 


```python
color=["green", "blue", "red", "green", "green", "red", 
 "blue", "black", "white", "yellow", "green", "yellow", 
 "green", "green", "green"]
pd.Series(color).mode()
```




    0    green
    dtype: object




```python
stats.mode(color)
```




    ModeResult(mode=array(['green'], dtype='<U6'), count=array([7]))



<div style="width:70%; border: 1px solid; border-radius: 5px; margin: 50px; padding:10px">
    <b><U>Data type</U></b><br><br>
In programming languages, data types are the standards for allocating memory for storing or operating data. Python basically includes five types of data types: numeric, character, list, tuple, and dictionary. However, new data types for specific purposes can be created based on these primitive data types. Packages such as numpy, pandas, and scipy used above use their respective data types, but they are data types created based on lists. A list is a form of grouping multiple values into one using square brackets, and has the form ['a','list','list', 2, 3]. Converting this form to numpy array type and pandas series type is as follows. 
   </div>


```python
x= ['a','list', 2, 3]
x
```




    ['a', 'list', 2, 3]




```python
np.array(x)
```




    array(['a', 'list', '2', '3'], dtype='<U21')




```python
pd.Series(x)
```




    0       a
    1    list
    2       2
    3       3
    dtype: object



``pd object mode()`` calculates the mode for the list variable that is the above nominal type. However, in order to calculate various statistics as well as the mode, it is necessary to convert a list variable (a qualitative variable) into a quantitative variable, which is a numerical type. For this conversion, you can apply ``LabelEncoder()``, a class from the preprocessing module of the Python package sklearn. In Python, a class is a type of function that contains several functions and objects within it. The process of applying a class is slightly different from that of a normal function. 

<div style="width:70%; border: 1px solid; border-radius: 5px; margin: 50px; padding:10px">
    <b><U>Package</U></b><br><br>
Python consists of a core program and various packages. The package is made for a specific area based on the core program, and the user uses it by importing the package to be used as the core program. The above-mentioned numpy, pandas, and scipy are representative packages used in data cleaning, analysis, statistics, and mathematical operations, and are used by attaching to the core program as follows. 
    </div>
	
```
	   import numpy as np
	   import pandas as pd
	   from scipy import stats
```

There are several ways to attach packages. 

<div style="width:70%; border: 1px solid; border-radius: 5px; margin: 50px; padding:10px">
    <b><U>class</U></b><br><br>
Python is made up of objects. When an object is simply expressed, it can be regarded as a name and space for storage. It is also simply a name, but it can also be a function that returns a result through a specific operation when data in an appropriate format is input. These objects have properties that are unique to them, called attributes. A class is an object for defining the activity area of an object. Therefore, it contains functions and attributes that can only be used within the class. These functions are denoted by the terms method or member function to distinguish them from ordinary functions. For example, to use the class LabelEncoder() applied above, create an object that will share all methods and attributes of this class.  
    </div>

```
  x=LabelEncoder()
``` 
 Object x can use all methods and attributes included in LabelEncoder(). In other words, all methods and properties defined on object x can only be used within that object. 



```python
from sklearn.preprocessing import LabelEncoder
```


```python
color=['white', 'red', 'white', 'red', 'black', 'red', 'black', 'red',
       'yellow', 'white', 'yellow', 'yellow', 'red', 'yellow', 'black']
col=LabelEncoder()
col.fit(color)
```




    LabelEncoder()




```python
list(col.classes_)
```




    ['black', 'red', 'white', 'yellow']




```python
color1=col.transform(color)
color1
```




    array([2, 1, 2, 1, 0, 1, 0, 1, 3, 2, 3, 3, 1, 3, 0])




```python
col.inverse_transform(color1)
```




    array(['white', 'red', 'white', 'red', 'black', 'red', 'black', 'red',
           'yellow', 'white', 'yellow', 'yellow', 'red', 'yellow', 'black'],
          dtype='<U6')



Determine the mode for color1 in the above result.


```python
val, count=stats.mode(color1)
print(f'mode: {val}, counts: {count}')
```

    mode: [1], counts: [5]



```python
col.inverse_transform([1])
```




    array(['red'], dtype='<U6')



Below are the records generated in the running race.
<div style="width:30%; border: 1px solid; border-radius: 5px; margin: 50px; padding:10px">
    1:00:05, 1:00:04,  0:53:53, 0:51:32,  1:00:09<br>
0:51:39, 1:00:07, 1:00:10, 1:00:42, 1:00:48
   </div>

It can be seen from this record that most of the time is close to an hour. However, the mode cannot be determined because no value appears more than once. In other words, it is difficult to determine the mode for a continuous variable like the one above. As a result, the mode is primarily used for categorical data. The ``np.digtize()`` function is applied to discretize the continuous variable to each range. This function divides the continuous variable into specified intervals and returns the interval to which each value belongs. 

<span style="color:blue;"><b>Example 3)</b></span><br>
&emsp;The following code divides 20 random numbers into 10 intervals and displays the interval in which each value is included. 


```python
np.random.seed(seed=0)
df=pd.DataFrame(np.around(np.random.randn(20), 3))
df.columns=['da']
df.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>da</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.764</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.400</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.979</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2.241</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.868</td>
    </tr>
  </tbody>
</table>
</div>




```python
bins=np.around(np.linspace(df.da.min(), df.da.max(), 10), 3)
print(bins)
```

    [-0.977 -0.619 -0.262  0.096  0.453  0.811  1.168  1.526  1.883  2.241]


<span style="color:blue;"><b>Example 4)</b></span><br>
&emsp;  Mode of the next object?


```python
x=np.array([8,8,2,3,1,5,0])
stats.mode(x)
```




    ModeResult(mode=array([8]), count=array([2]))



<span style="color:blue;"><b>Example 5)</b></span><br>
&emsp; Find the mode of the next object and the frequency of each value in that object ?


```python
x=np.array([5, 5, 3, 6, 2, 4, 5, 9, 5, 5, 2, 5])
np.unique(x, return_counts=True)
```




    (array([2, 3, 4, 5, 6, 9]), array([2, 1, 1, 6, 1, 1]))




```python
x1=pd.DataFrame(x)
x1.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>




```python
x1.mode()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div>




```python
x1.value_counts()
```




    5    6
    2    2
    3    1
    4    1
    6    1
    9    1
    dtype: int64




```python
stats.mode(x1)
```




    ModeResult(mode=array([[5]]), count=array([[6]]))



### Mean 
As mentioned above, for continuous variables such as ratios, the mode of the data set cannot be determined. Instead, as in Equation 1, the average is used as a measure of centroid. This value is called the <span style="color:teal;">**mean**</span>.  
<br/><br/>
$$\begin{align}\tag{1}
		\mu&=\frac{\sum_{i=0}^N x_i}{N}\\
		\mu&:\; \text{mean}\\
		x&:\; \text{data}\\
		N&:\; \text{size}
	\end{align}$$
<br/>
  For example, the following is a student's grades for the middle and final semesters of the first and second semesters. Calculating the average of them gives: 
<br/><br/>
 $$ \begin{aligned}
	\text{grade}&=[6, 8, 9, 5]\\
	\mu&=\frac{6+8+9+5}{4}	
\end{aligned}$$
<br/>
The **mean** can be calculated using a loop as shown in the following code, but can be determined by applying the ``np.mean()`` function.


```python
grade=[6, 8, 9, 5]
total=0
for i in grade:
    total=total+i
total
```




    28




```python
mu=total/len(grade)
mu
```




    7.0




```python
np.mean(grade)
```




    7.0



Typically, the mean of each data x<sub>i</sub> in data set X is denoted by &mu;<sub>x</sub> or $\bar {x}$. Therefore, the above expression can be expressed as 
<br/><br/>
$$\begin{align}
\text{Mean}&=\frac{\text{Add of all values}}{\text{number of values}}\\\\
  \overline{x}&=\frac{\sum^n_{x_i}x_i}{n}\\
  &=\mu
\end{align}$$

<span style="color:blue;"><b>Example 6)</b></span><br/>
&emspl; Calculate the mean from the following frequency table.

|value| frequency|
|:---:| :---:|
|2| 4|
|5| 8|
|8 |6|

The frequency of each value is presented, and the sum of the data is calculated as the sum of value × frequency . The average is calculated as:<br/><br/>

$$\mu=\frac{2 \cdot 4 + 5 \cdot 8 + 8 \cdot 6}{4 + 8 + 6}$$

It is more useful to apply matrix operations when the number of values or the number of variables is large. The following code uses the ``np.dot()`` function to apply a matrix product that works as in Equation 2.<br/><br/>

\begin{equation}\tag{2}
	\begin{bmatrix}x_1&x_2&\cdots&x_n\end{bmatrix}
	 \begin{bmatrix}f_1\\f_2\\ \vdots \\ f_n\end{bmatrix} =x_1f_1+x_2f_2+\cdots+x_nf_n
\end{equation}




```python
value=np.array([2,5,8])
frequency=np.array([[4],[8],[6]])
total=np.dot(value, frequency)
total
```




    array([96])




```python
mu=total/np.sum(frequency)
np.round(mu, 2)
```




    array([5.33])



<span style="color:blue;"><b>Example 7)</b></span>

&emsp; Determine the data size if the mean is 15 and the sum is 315.
$$\begin{align} 15 &=\frac{315}{n} \\ 
n&=\frac{315}{15} \end{align}$$



```python
mu=15
total =315
n=total/mu
n
```




    21.0



The following data set contains one that differs significantly from the others, and these values are called <span style="color:teal"><b>outlier</b></span>. The mean covers the sum of all numbers as shown in Equation 1. Therefore, the mean is inherently very sensitive to these outliers.


```python
np.random.seed(0)
data=np.random.randint(1, 5, 10)
data
```




    array([1, 4, 2, 1, 4, 4, 4, 4, 2, 4])




```python
data.mean()
```




    3.0




```python
data1=np.append([100], [data[1:]])
data1
```




    array([100,   4,   2,   1,   4,   4,   4,   4,   2,   4])




```python
data1.mean()
```




    12.9




```python
data[1:].mean()  #mean excluding outliers
```




    3.2222222222222223



Averages provide an excellent central location of the data set, along with adjustments for outliers, etc. However, it is very important to recognize that the mean by itself is not accurate enough to judge all the information about that data set. To increase this accuracy, you need to increase the size of the data. 

### Median
The center of the data is the point where much of the data is concentrated. The mean is a method of determining the point, but there is a possibility of distorting the center of the whole due to the presence of outliers, etc. The median can be used as another central measure to compensate for the weakness of the mean.

For example, for a diet prescription for a group of 9 people, it is said that they are classified into weak and strong. The rationale for this prescription may present a problem for the following decision when classifying the group based on the average weight of 43 kg. 


```python
weight=np.array([38, 35, 45, 30, 48, 33, 42, 39,100])
weight
```




    array([ 38,  35,  45,  30,  48,  33,  42,  39, 100])




```python
weight.mean()
```




    45.55555555555556




```python
weight[:-1].mean()
```




    38.75



As the code shows, the weight of one member of the group differs significantly from the rest. That is, it contains values that are outliers. In this state, the average weight should be about 45.6 kg, suggesting prescription strength. However, if outliers are excluded, it is less than the suggested value and a weak prescription is issued. If such an outlier exists, the mean is very sensitive to the value and has the potential to act as a basis for unfavorable judgments. Instead of the mean, a value located in the middle of the data can be used as a position value representing the center. These measurements are defined as the <mark>median</mark>. <br>

<div style="width:70%; border: 1px solid; border-radius: 5px; margin: 50px; padding:10px"> 
    <b>Median</b><br>
- Sorts all values in ascending or descending order.
- Determine the total number of data (n)
- determine the middle value 
$$\begin{aligned} 
&n=\text{odd} \rightarrow \text{round index for median}=\frac{n}{2}\\
&\begin{aligned}n=\text{even} \rightarrow \text{index for median}&=[\frac{n}{2},\; \frac{n}{2}+1]\\
&=\text{average of two position values }\end{aligned}
\end{aligned}$$
</div>

Sorting the data can be done by applying the function ``np.sort()``. In this example, the number of data is 9, so the median is $\displaystyle \frac{9}{2}=4.5$. Since it is odd, this index rounds up to determine the 5th value as the median. In python, the index starts at 0, so the following code calls the value located at the 4th index of the object.


```python
weightSort=np.sort(weight)
weightSort
```




    array([ 30,  33,  35,  38,  39,  42,  45,  48, 100])




```python
weightSort[4]
```




    39



The median can be calculated directly using ``np.median()``.


```python
np.median(weight)
```




    39.0



<span style="color:blue;"><b>Example 8)</b></span>

&emsp; Determines the median of 34, 12, 5, 42, 7, 55.


```python
d=np.array([34, 12, 5, 42, 7, 55])
dsort=np.sort(d)
dsort
```




    array([ 5,  7, 12, 34, 42, 55])




```python
#n=6, even
medIdx=len(d)/2
medIdx
```




    3.0




```python
med=(dsort[2]+dsort[3])/2
med
```




    23.0




```python
np.median(d)
```




    23.0



## Variation
<mark>Variation</mark> or <mark>spread</mark> indicates the degree of spread of data and is the basic information that describes the characteristics of data. You can use variation along with location information such as ***mean*** to describe the distribution of data. For example, the following data are Dow Jones index data for a period of time. Although this data is continuous, it is converted into a categorical variable by dividing each value into specific intervals as shown in the following table. 

<table>
<tbody style="border:1px solid black;">
<tr>
<th rowspan=2><center>group</center></th>
<th colspan=2><center>Range</center></th>
</tr>
<tr>
<th>Lower</th>
<th>Upper</th>
</tr>
<tr>
<td>1</td>	<td>29978	</td> <td>30515</td>
</tr>
<tr>
<td>2</td><td>	30515	</td><td>31048</td>
</tr>
<tr>
			<td>3</td><td>	2998.12</td><td>3018.12</td>
</tr>
<tr>
			<td>4</td><td>	31048</td><td>	31581</td>
</tr>
<tr>
			<td>5</td><td>	31581</td><td>	32114</td>
</tr>
<tr>
			<td>6</td><td>	32114</td><td>32647</td>
</tr>
<tr>
		<td>	7</td><td>	32647</td><td>33179</td>
</tr>
<tr>
		<td>	8</td><td>	33179	</td><td>33712</td>
</tr>
<tr>
		<td>	9</td><td>	33712	</td><td>34245</td>
</tr>
<tr>
			<td>10</td><td>	34245</td><td>	34778</td>
</tr>
<tr>
			<td>11</td><td>	34778</td><td>	$\sim$ </td>
</tr>
</tbody>
</table>

Various financial data can be obtained using the Python package Python library ``FinanceDataReader``. The following material is a call to the Dow Jones index for a specified period using the ``DataReader()`` function of this package. Since this data is continuous type, the ``pd.cut()`` function is used to convert it to a categorical type.This function is more convenient than the ``np.digitize()`` function because it returns the list result directly by specifying the interval. You can also use ``np.histogram()`` to represent the frequency of each interval.



```python
import FinanceDataReader as fdr
st=pd.Timestamp(2021,1, 1)
et=pd.Timestamp(2021, 11,23)
da=fdr.DataReader('DJI', st, et)['Close']
da.head(2)
```




    Date
    2021-01-04    30223.89
    2021-01-05    30391.60
    Name: Close, dtype: float64




```python
da1=pd.cut(da, bins=9, labels=range(1,10), retbins=True)
da1[0].head(3)
```




    Date
    2021-01-04    1
    2021-01-05    1
    2021-01-06    2
    Name: Close, dtype: category
    Categories (9, int64): [1 < 2 < 3 < 4 ... 6 < 7 < 8 < 9]




```python
np.around(da1[1], 0)
```




    array([29976., 30699., 31416., 32132., 32849., 33565., 34282., 34998.,
           35715., 36431.])




```python
np.histogram(da, bins=9)
```




    (array([ 7, 24, 14,  9, 13, 38, 66, 36, 19]),
     array([29982.62, 30699.15, 31415.68, 32132.21, 32848.74, 33565.27,
            34281.8 , 34998.33, 35714.86, 36431.39]))



Each interval frequency of the above result can be calculated directly by applying the ``value_counts()`` method in pandas package and ``mode()`` method in the package is also used to calculate the mode of data. 


```python
fre=da1[0].value_counts()
fre
```




    7    66
    6    38
    8    36
    2    24
    9    19
    3    14
    5    13
    4     9
    1     7
    Name: Close, dtype: int64




```python
da1[0].mode()
```




    0    7
    Name: Close, dtype: category
    Categories (9, int64): [1 < 2 < 3 < 4 ... 6 < 7 < 8 < 9]



The mode for this data is 7. Among the above results, the result of ``value_counts()`` shows the frequency of each interval, and a dot plot can be created as shown in Figure 1.1. This figure indicates the degree of distribution of the data and gives an approximate shape. 


```python
import matplotlib.pyplot as plt
for i, j in zip(fre.index, fre.values):
    plt.scatter(np.repeat(i, j), range(1, j+1), s=100)
plt.xlabel("Group", size="13", weight="bold")
plt.ylabel("Frequency", size="13", weight="bold")
plt.text(1, -20, 'Figure 1. Dotplot.', size="15", weight="bold")
plt.show()
```


    
![png01](https://github.com/enshs/enshs.github.io/blob/master/_posts/image/desStat01.png)
    


Figure 2 is a dotplot of different data. It can be seen that this data has a larger difference (spread of data) between the minimum and maximum values compared to Figure 1. Since this difference is the variation of the data, it can be seen that the variation of the data in Figure 2 is large compared to Figure 1. 


```python
st=pd.Timestamp(2010,1, 1)
et=pd.Timestamp(2021, 11,23)
da2=fdr.DataReader('DJI', st, et)['Close']
```


```python
da2Cat=pd.cut(da2, bins=9, labels=range(1,10), retbins=True)
fre2=da2Cat[0].value_counts()
fre2[:3]
```




    3    758
    1    541
    6    477
    Name: Close, dtype: int64




```python
for i, j in zip(fre2.index, fre2.values):
    plt.scatter(np.repeat(i, j), range(1, j+1), s=100)
plt.xlabel("Group", size="13", weight="bold")
plt.ylabel("Frequency", size="13", weight="bold")
plt.text(1, -300, 'Figure 2. Dotplot.', size="15", weight="bold")
plt.show()
```


    
![png02](https://github.com/enshs/enshs.github.io/blob/master/_posts/image/desStat02.png)
    


<div style="width:70%; border: 1px solid; border-radius: 5px; margin: 50px; padding:10px">
    <b>Spread(Variation)</b><br>
- Represents the difference between the maximum and minimum values of the data or the difference from the centroid
- If the difference between the values is large, the spread increases. 
   </div>
   <br>
Figures 1 and 2 are dotplots showing the fluctuations, but as the size of the data increases, the distinction can become blurry in the figure. In this case, numerical values representing fluctuations are used, and the types are as follows. 

- Range
- Mean Absolute Deviation, MAD
- Variance
- Stadard Deviation

### Range
It uses the range of the data set as a method of measuring variance (spread). As in Equation 3, the range represents the difference between the maximum and minimum values. 

$$\begin{equation}\tag{3}
	\text{range}=\text{maximum}-\text{minimum}
\end{equation}$$

This value can be calculated as the difference between the two values after determining the maximum and minimum values of the data set using the numpy functions ``np.max()`` and ``np.min()``. The following is the calculation of the range after extracting 50 random numbers between [1, 100).


```python
d=np.random.randint(1,100, 50)
d
```




    array([22, 37, 88, 71, 89, 89, 13, 59, 66, 40, 88, 47, 89, 82, 38, 26, 78,
           73, 10, 21, 81, 70, 80, 48, 65, 83, 89, 50, 30, 20, 20, 15, 40, 33,
           66, 10, 58, 33, 32, 75, 24, 36, 76, 56, 29, 35,  1,  1, 37, 54])




```python
dmax, dmin=np.max(d), np.min(d)
dmax, dmin
```




    (89, 1)




```python
rng=dmax-dmin
rng
```




    88



<span style="color:blue;"><b>Example 9)</b></span> <br>
&emsp; Calculate the range of the following data.<br/>


```python
A=set([4, 6, 2, 4, 6, -4, -7, 45])
B=set([4, 6, 2, 4, 6, -4, -7, 145])
print(f'A:{A}\nB:{B}')
```

    A:{2, 4, 6, 45, -7, -4}
    B:{2, 4, 6, 145, -7, -4}



```python
rng_A=max(A)-min(A)
rng_B=max(B)-min(B)
print(f'range of A:{rng_A}\nrange of B:{rng_B}')
```

    range of A:52
    range of B:152


In Example 9, the two groups A and B are equal except for one value. However, that value of B can be regarded as an outlier with a significant difference compared to the other values, and the value of that value makes the range of the two groups very different. In other words, the range is a simple yielding result, but is *very sensitive to outliers*. 

### Quantile
A quantile is one of many ways to measure variation. For example, the following data contains significantly large values that can be considered outliers. In such cases, the range cannot accurately represent the variability characteristics of the data set.


```python
x=np.array([1,2, 4,5,6,8,8,9,105])
x
```




    array([  1,   2,   4,   5,   6,   8,   8,   9, 105])




```python
rng=x.max()-x.min() #range
rng
```




    104



There are cases where it is advantageous to understand the variability of data as a quantile, which is expressed by dividing the data into several small groups instead of the overall range of the data. A quartile means that it is roughly divided into 4 parts. It is calculated by the following process. 
- step 1) sort in ascending order
- step 2) Determine the median (Q<sub>2</sub>)
- step 3) Determines the median value between small values (Q<sub>1</sub>) and large values (Q<sub>3</sub>) based on the median value determined in step 2. 

With the above process, Q<sub>1</sub>, Q<sub>2</sub> and Q<sub>3</sub> for {1, 2, 4, 5, 6, 8, 8, 9, 105} of the example data are 4, 6, and 8, respectively. This quantile can be determined using numpy's quantile() function. 


```python
np.quantile(x, [0.25, 0.5, 0.75])
```




    array([4., 6., 8.])



Apply a boxplot (Figure 3) to visualize the above results. This graph uses the boxplot() function of the Python library matplotlib.


```python
plt.boxplot((1,2, 4,5,6,8,8,9,105))
plt.title("BoxPlot based on quantile")
plt.text(0.5,-30,'Figure.3 Quantile and boxplot.', size="15", weight="bold")
plt.show()
```


    
![png03](https://github.com/enshs/enshs.github.io/blob/master/_posts/image/desStat03.png)
    


As shown in Figure 1.3, the top and bottom of the box plot body (square) represent Q<sub>1</sub> and Q<sub>3</sub>, respectively, and the value corresponding to the middle 50% of the data (Q<sub>2</sub>) exists in this part. This part is called **Interquartile Range** and is denoted by IQR.  <br><br>

<center><b>IQR=Q<sub>3</sub>-Q<sub>1</sub></b></center>
<br>
The red line within the box represents Q<sub>2</sub>. The lower and upper wing lines of the box represent the minimum and maximum values, respectively. Points outside this are considered outliers. 

<span style="color:blue;">**Example 10)** </span><br>
&emsp;	Create a quartile, IQR, and boxplot of two groups of random numbers. 


```python
da=np.random.randint(1, 100, size=(2,30))
da
```




    array([[ 6, 39, 18, 80,  5, 43, 59, 32,  2, 66, 42, 58, 36, 12, 47, 83,
            92,  1, 15, 54, 13, 43, 85, 76, 69,  7, 69, 48,  4, 77],
           [53, 79, 16, 21, 59, 24, 80, 14, 86, 49, 50, 70, 42, 36, 65, 96,
            70, 95,  1, 51, 37, 35, 49, 94,  4, 99, 43, 78, 22, 74]])




```python
q=np.quantile(da, [0.25, 0.5, 0.75], axis=1)
q
```




    array([[13.5 , 35.25],
           [43.  , 50.5 ],
           [68.25, 77.  ]])



The axis is set to 1 in the ``np.quantile()`` function in the code above. This is row-based. So the result of that function is:

| |Group1(row1)|Group2(row2)|
|:---:|:---:|:---:|
|Q<sub>1</sub>|33.25| 29.5|
|Q<sub>2</sub>|51.| 49. |
|Q<sub>3</sub>|84.75 |64.|
            
IQR will be the difference between rows 1 and 3 of the above result object. IQR can be calculated directly from data using the ```iqr()``` function in the stats module of the scipy package. A boxplot of these results is shown in Figure 4.  


```python
plt.boxplot(da.T)
plt.title("BoxPlot of two group")
plt.text(0.5, -30, "Figure 4. Two groups of boxplots.", size="15", weight="bold")
plt.show()
```


    
![png04](https://github.com/enshs/enshs.github.io/blob/master/_posts/image/desStat04.png)
    


### Mean Absolute Deviation(MAD)

The range is the difference between the maximum and minimum values, which is very sensitive to outliers. Instead, the difference between each value around a criterion such as the mean can be used as the variance of the data. In other words, the difference between the mean and each value is called **deviation** and the mean of all deviations in the data can be used as a measure of variance.  

The deviation is the difference between each observation and the mean. That is, the mean deviation is calculated as follows:
<br><br>
$$\begin{align}
	\text{mean deviation}&=\frac{\sum^n_{i=1}(x_i-\overline{x})}{n}\\
	n&: \text{data size}\end{align}$$
<br>    
<span style="color:blue;">**Example 11)**</span><br>
&emsp; Calculate the mean deviation of the following data. 


```python
d=np.array([4, 5, 6, 8, 10, 11, 12])
d
```




    array([ 4,  5,  6,  8, 10, 11, 12])




```python
mu=np.mean(d)
mu
```




    8.0




```python
dev=np.array([i-mu for i in d])
dev
```




    array([-4., -3., -2.,  0.,  2.,  3.,  4.])




```python
devTotal=dev.sum()
devTotal
```




    0.0




```python
devMean=devTotal/len(dev)
devMean
```




    0.0



Since the mean deviation is the sum of the differences between the values around the mean of the data, it is always 0 as shown in the above result. These results do not provide any clues as to the interpretation of variability for the data. Instead, **Mean Absolute Deviation**(MAD), calculated by converting each variation to a positive number, as in Equation 4, can be made a useful indicator. 
<br><br>
$$\begin{align} \tag{4}
		\text{MAD}&=\frac{\sum^n_{i=1}\vert x_i-\overline{x}\vert}{n}\\
		n&: \text{data size}\end{align}$$
        
MAD can be computed without intermediate calculations using ``DataFrame.mad()`` method in the pandas package.


```python
ad=np.array([abs(i-mu) for i in d])
ad
```




    array([4., 3., 2., 0., 2., 3., 4.])




```python
adTotal=ad.sum()
adTotal
```




    18.0




```python
adMean=adTotal/len(ad)
adMean
```




    2.5714285714285716




```python
mad=pd.DataFrame(d).mad()
mad
```




    0    2.571429
    dtype: float64



However, MAD has the disadvantage of being very insensitive to outliers. 

### Variance

In order to measure the spread of data, it is possible to apply a square instead of an absolute value with a concept similar to MAD. That is, it is calculated as Equation 5, and this result is called the**mean squared deviation**(msd) or **variance**. Usually the variance is denoted as &sigma;<sup>2</sup>. 

$$\begin{align} \tag{5}
\sigma^2&=\frac{\sum^n_{i=1}(x_i-\overline{x})^2}{n}\\
&\sigma^2:\text{variance}\\
		&n: \text{sample size} \end{align}$$
        
Figure 5 plots MAE and variance functions for data with mean &mu;. 


```python
mu=0
x=np.linspace(1,-1, 100)
plt.plot((x-mu)**2, label=r"MSD, $(x-\mu)^2$")
plt.plot(abs(x-mu), label=r"MSE, $|x-\mu|$")
plt.legend(loc="best")
plt.xticks([])
plt.yticks([])
plt.text(0, -0.3, "Figure 5. MSE vs MAD.", size=15, weight="bold")
plt.show()
```


    
![png05](https://github.com/enshs/enshs.github.io/blob/master/_posts/image/desStat05.png)
    


As shown in Figure 5, MAE is a straight line and variance is a quadratic curve. Deviation is an important parameter for statistical estimation based on probability. Statistical models for estimating new values based on existing data are built based on the point where the deviation is minimal. Therefore, the function that calculates the deviation should be written in the form of a function that can determine the minimum deviation, and the variance in the form of a quadratic curve that can mathematically calculate the instantaneous change is advantageous. 

<span style="color:blue;"><b>Example 12)</b></span><br>
&emsp; The mean and standard deviation of the selling prices of two products for a company are:<br>
&emsp; Compare product variations. 

||Mean|Variance|
|:---:|:---:|:---:|
|Product A| 11950 | 587.8|
|Product B| 35879 | 985.8|

Product B has a large variance, so it has wider variance. 

<span style="color:blue;"><b>Example 13)</b></span><br>
&emsp; The following data are the scores of 6 randomly selected students from a class. Determine the variance of this data. 


```python
x=np.array([90, 65, 95 ,75, 70, 85])
x
```




    array([90, 65, 95, 75, 70, 85])




```python
mu=x.mean()
mu
```




    80.0



&emsp; Calculates the deviation and squared deviation of each value from the mean. 

||Score|Deviation<br>=$x-\bar{x}$| Squared deviation<br>=$(x-\bar{x})^2$|
|:---:|:---:|:---:|:---:|
|A| 90.0 |10.0| 100.0|
|B| 65.0 |-15.0 |225.0|
|C| 95.0 |15.0| 225.0|
|D| 75.0 |-5.0| 25.0|
|E| 70.0 |-10.0| 100.0|
|F| 85.0| 5.0| 25.0|

From the squared deviations in the table above, the variance can be calculated as follows:  

$$\begin{align}
	\sigma^2&=\frac{100.0+225.0+225.0+25.0+100.0+25.0}{6}\\
	&=116.7
\end{align}$$

The variance can be calculated by applying the ``np.var()`` or ``object.var()`` methods.


```python
np.around(x.var(), 1)
```




    116.7



The process of calculating variance as in Example 11 can be summarized as follows. 
1. determine the average
2. Calculates the difference between each value and the mean (=deviation)
3. Calculate the square of each deviation (=squared deviation)<br>
	The sum of square deviations is commonly denoted SS.
4. The variance is determined by dividing the sum of squared deviations by the size of the data.<br>
&emsp;	$\displaystyle \frac{\text{SS}}{\text{sample size}}$
<br><br>
<span style="color:blue;"><b>example 14)</b></span><br>
&emsp;	Determine the variance of the data with SS=486, n=120 (number of samples). 

$$\sigma^2=\frac{488}{120}=4.05$$

### Standard Deviation

Variance has the disadvantage of not being able to use the raw data unit as the square of the deviation. For example, the variance of data over time (sec) has units of sec<sup>2</sup>. This makes it difficult to directly interpret the data using variance. To restore these units to their original values, apply the square root of the variance as in Equation 6. This result is called **standard deviation** and is denoted by &sigma;.
    
$$\begin{align}\tag{6}
	\sigma= \sqrt{\frac{\sum^n_{i=1}(x_i-\bar{x})^2}{n}}
\end{align}$$

The standard deviation can be calculated with the ``np.std()`` function or the Pandas ``object.std()`` method. 

<span style="color:blue;"><b>Example 15)</b></span><br>
&emsp; Determine the variance and standard deviation of the following objects. 


```python
x=np.array([615, 949, 1173, 172, 940])
mu=x.mean()
SS=np.sum((x-mu)**2)
vari=SS/len(x)
std1=np.sqrt(vari)
print(f'mean:{mu}, Squared Sum:{SS}\nVariance:{round(vari,2)}, Standard Deviation:{round(std1,2)}')
```

    mean:769.8, Squared Sum:604978.8
    Variance:120995.76, Standard Deviation:347.84



```python
var2, std2=x.var(), x.std()
print(f'variance: {np.around(var2, 2)}\nStamdard Deviation:{ np.around(std2, 2)}')
```

    variance: 120995.76
    Stamdard Deviation:347.84


<span style="color:blue;"><b>Example 13)</b></span><br>
The data has 20 values and the sum of squares is 95220. Standard Deviation? 


```python
np.sqrt(95220/20)
```




    69.0



<span style="color:blue;"><b>Example 16)</b></span><br>
The standard deviation of the data with 24 values is 33. Sum of squares of this data? 

$$24 \cdot 33^2=26136$$

<span style="color:blue;"><b>Example 17)</b></span><br>
A scored 78 points on the exam of which the average is 72 points.  Determine the standard deviation in favor of A if the standard deviation of the test is <br>
<center>(1) s=2 &emsp; (2) s=3 &emsp; (3) s=4 </center>

A small variance in the data means that the values increase in concentration at a specific point. Also, since the score of A is larger than the mean, the smaller the standard deviation, the higher the probability of being at the top. Therefore, case (1) would be most advantageous. 
<br>
In statistical analysis, the entire set of interest for obtaining information is called a **population**, and a part of the population is called a **sample**. In general, it is often difficult to obtain a population. Therefore, the purpose of statistical analysis is to estimate the characteristics of a population from a sample that is part of the population. Since the sample size is adjustable and finite, statistics such as sum and mean can be determined. Because of this, not all values are stochastic. For example, the sum of data consisting of [1, 3, 5, 1] is 10. Since the total of this data is in a fixed state, if you know 3 values of the data, the rest is automatically assigned, so out of the 4 values of this data, only 3 values can be used as random variables. This is called the **degree of freedom**, and in our example, the degree of freedom is 3. Thus, for a finite sample of n values, the degrees of freedom are n-1. 

<div style="width:70%; border: 1px solid; border-radius: 5px; margin: 50px; padding:10px">
    <b>Degree of freedom</b><br><br>
The number of independent pieces of information used in the process of calculating a statistical estimate is called the degrees of freedom. 
   </div>
   <br>
In the case of a population, degrees of freedom cannot be considered because statistics such as overall size or mean are not generally known as the object of estimation. However, since the sample has a finite size, the degrees of freedom must be considered. If the sample size is very large, the difference between n and n-1 is negligible. However, a small sample can make a big difference in the results. Therefore, the degrees of freedom must be taken into account in the mean or variance and standard deviation. The calculation of the statistic in the population and sample, whether or not degrees of freedom is considered, is as follows:  

<table style="border:2px solid;">
    <tbody>
        <tr>
            <th colspan=2, style="border:1px solid;"><center>Population</center> </th>
            <th colspan=2, style="border:1px solid;"><center>Sample</center></th>
        </tr>
        <tr>
            <td style="border:1px solid; text-align:left;">Mean</td>
            <td style="border:1px solid;text-align:left;">$\displaystyle \mu=\frac{\sum x}{N}$ </td>
            <td style="border:1px solid;text-align:left;">Mean</td>
            <td style="border:1px solid;text-align:left;">$\displaystyle \overline{x}=\frac{\sum x}{n-1}$</td>
        </tr>
		<tr>
            <td style="border:1px solid;text-align:left;">Variance</td>
            <td style="border:1px solid;text-align:left;">$\displaystyle \sigma^2=\frac{\sum (x-\mu)^2}{N}$</td>
            <td style="border:1px solid;text-align:left;">Variance </td>
            <td style="border:1px solid;text-align:left;">$\displaystyle s^2=\frac{\sum (x- \overline{x})^2}{n-1}$</td>
        </tr>
       <tr>
           <td style="border:1px solid;text-align:left;">Standard Deviation</td>
           <td style="border:1px solid;text-align:left;">$\displaystyle \sigma=\sqrt{\sigma^2}$</td>
           <td style="border:1px solid;text-align:left;">Standard Deviation</td>
           <td style="border:1px solid;text-align:left;"> $\displaystyle s=\sqrt{s^2}$</td>
    </tr>
    </tbody>
    </table>
    
 
### Variation Coefficient

It is used to compare two materials. For example, say that the mean and standard deviation of a group's height and weight are: 

|Item|Mean|Standard Deviation|
|:---:|:---:|:---:|
|Height|165 cm|19 cm |
|Weight|70 kg|12.9 kg|

In the above two items, it can be said that numerically the height shows a greater fluctuation than the weight. However, since the units of the two items are different, the difference can be clearly indicated by comparing the results with the units removed rather than just comparing the size of the numbers. As the result of the following expression shows, the value obtained by dividing the standard deviation by the mean in each item can be used as a comparison index with other items because the unit is removed. 

$$\begin{align}
	&\text{heiht}: \frac{19\, \text{cm}}{165 \,\text{cm}}=0.185\\
	&\text{weight}: \frac{12.9\, \text{kg}}{70\, \text{kg}}=0.115
\end{align} $$

From the above result, it can be seen that the change in height is larger than the change in weight. This measure is called **coefficient of variance**(Cv) and is calculated as Equation 7. 

$$ \begin{equation}\tag{7} 
	\text{Cv}=\frac{\sigma}{\mu}\quad \text{or}\quad \frac{s}{\overline{x}}
\end{equation}$$

<span style="color:blue;"><b>Example 18)</b></span><br>
&emsp; Calculate:
1. The standard deviation of the population of C<sub>v</sub>=0.872, &mu;=7.2?


```python
 0.872*7.2
```




    6.2784



2. The standard deviation of the population of C<sub>v</sub>=0.52, &sigma;=18?


```python
round(18/0.52,3)
```




    34.615


